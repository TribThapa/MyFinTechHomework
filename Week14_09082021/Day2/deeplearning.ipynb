{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Wine Quality Predictor\n",
    "\n",
    "This notebook shows how to build a deep learning model to predict the quality score of different wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv(r'C:\\Users\\TribThapa\\Desktop\\Thapa\\ResearchFellow\\Courses\\FinTech_Bootcamp_MonashUni2021\\monu-mel-virt-fin-pt-05-2021-u-c\\Activities\\Week 14\\2\\01-Ins_Deep_Learning\\Resources\\winequality.csv',\n",
    "                 delimiter=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features (X) and target (y) sets\n",
    "X = df.iloc[:, 0:11].values\n",
    "\n",
    "y = df[\"quality\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - shallow neural net\n",
    "number_hidden_nodes = 8\n",
    "\n",
    "number_input_features = 11\n",
    "\n",
    "nn = Sequential()\n",
    "\n",
    "# Hidden layer\n",
    "nn.add(Dense(units=number_hidden_nodes,\n",
    "             input_dim=number_input_features,\n",
    "             activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(Dense(units=1,\n",
    "             activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 5s 18ms/step - loss: 882.1615 - mse: 882.1615 - val_loss: 583.5133 - val_mse: 583.5133\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 495.4577 - mse: 495.4577 - val_loss: 315.2725 - val_mse: 315.2725\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 260.8454 - mse: 260.8454 - val_loss: 142.7911 - val_mse: 142.7911\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 112.0755 - mse: 112.0755 - val_loss: 48.2749 - val_mse: 48.2749\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 38.7635 - mse: 38.7635 - val_loss: 14.3654 - val_mse: 14.3654\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 14.3411 - mse: 14.3411 - val_loss: 7.7383 - val_mse: 7.7383\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 8.5644 - mse: 8.5644 - val_loss: 7.5319 - val_mse: 7.5319\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 7.4658 - mse: 7.4658 - val_loss: 7.4426 - val_mse: 7.4426\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 6.9717 - mse: 6.9717 - val_loss: 7.0828 - val_mse: 7.0828\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 6.5186 - mse: 6.5186 - val_loss: 6.6725 - val_mse: 6.6725\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 6.1024 - mse: 6.1024 - val_loss: 6.2603 - val_mse: 6.2603\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5.7358 - mse: 5.7358 - val_loss: 5.8709 - val_mse: 5.8709\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5.3709 - mse: 5.3709 - val_loss: 5.5284 - val_mse: 5.5284\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5.0480 - mse: 5.0480 - val_loss: 5.2189 - val_mse: 5.2189\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4.7593 - mse: 4.7593 - val_loss: 4.8545 - val_mse: 4.8545\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.4809 - mse: 4.4809 - val_loss: 4.5691 - val_mse: 4.5691\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4.2510 - mse: 4.2510 - val_loss: 4.2880 - val_mse: 4.2880\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 4.0219 - mse: 4.0219 - val_loss: 4.0986 - val_mse: 4.0986\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 3.8261 - mse: 3.8261 - val_loss: 3.8853 - val_mse: 3.8853\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - ETA: 0s - loss: 3.5507 - mse: 3.550 - 0s 7ms/step - loss: 3.6239 - mse: 3.6239 - val_loss: 3.6220 - val_mse: 3.6220\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 3.4510 - mse: 3.4510 - val_loss: 3.4410 - val_mse: 3.4410\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3.2924 - mse: 3.2924 - val_loss: 3.2584 - val_mse: 3.2584\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.1423 - mse: 3.1423 - val_loss: 3.0690 - val_mse: 3.0690\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.0072 - mse: 3.0072 - val_loss: 2.8868 - val_mse: 2.8868\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.8716 - mse: 2.8716 - val_loss: 2.7568 - val_mse: 2.7568\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.7607 - mse: 2.7607 - val_loss: 2.5826 - val_mse: 2.5826\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.6392 - mse: 2.6392 - val_loss: 2.4675 - val_mse: 2.4675\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5306 - mse: 2.5306 - val_loss: 2.3825 - val_mse: 2.3825\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.4328 - mse: 2.4328 - val_loss: 2.2729 - val_mse: 2.2729\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.3266 - mse: 2.3266 - val_loss: 2.1200 - val_mse: 2.1200\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.2363 - mse: 2.2363 - val_loss: 2.0512 - val_mse: 2.0512\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.1573 - mse: 2.1573 - val_loss: 1.9571 - val_mse: 1.9571\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.0693 - mse: 2.0693 - val_loss: 1.8677 - val_mse: 1.8677\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.9910 - mse: 1.9910 - val_loss: 1.7775 - val_mse: 1.7775\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.9185 - mse: 1.9185 - val_loss: 1.6823 - val_mse: 1.6823\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.8489 - mse: 1.8489 - val_loss: 1.6094 - val_mse: 1.6094\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1.7818 - mse: 1.7818 - val_loss: 1.5533 - val_mse: 1.5533\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.7273 - mse: 1.7273 - val_loss: 1.4717 - val_mse: 1.4717\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.6655 - mse: 1.6655 - val_loss: 1.4277 - val_mse: 1.4277\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.6167 - mse: 1.6167 - val_loss: 1.3797 - val_mse: 1.3797\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.5679 - mse: 1.5679 - val_loss: 1.3247 - val_mse: 1.3247\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.5162 - mse: 1.5162 - val_loss: 1.2722 - val_mse: 1.2722\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.4689 - mse: 1.4689 - val_loss: 1.2255 - val_mse: 1.2255\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.4268 - mse: 1.4268 - val_loss: 1.1910 - val_mse: 1.1910\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.3904 - mse: 1.3904 - val_loss: 1.1563 - val_mse: 1.1563\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.3539 - mse: 1.3539 - val_loss: 1.1192 - val_mse: 1.1192\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.3213 - mse: 1.3213 - val_loss: 1.0916 - val_mse: 1.0916\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.2927 - mse: 1.2927 - val_loss: 1.0673 - val_mse: 1.0673\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.2654 - mse: 1.2654 - val_loss: 1.0403 - val_mse: 1.0403\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.2403 - mse: 1.2403 - val_loss: 1.0185 - val_mse: 1.0185\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 1.2163 - mse: 1.2163 - val_loss: 1.0004 - val_mse: 1.0004\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.1972 - mse: 1.1972 - val_loss: 0.9825 - val_mse: 0.9825\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1.1748 - mse: 1.1748 - val_loss: 0.9662 - val_mse: 0.9662\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1.1568 - mse: 1.1568 - val_loss: 0.9533 - val_mse: 0.9533\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.1383 - mse: 1.1383 - val_loss: 0.9423 - val_mse: 0.9423\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.1268 - mse: 1.1268 - val_loss: 0.9319 - val_mse: 0.9319\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.1087 - mse: 1.1087 - val_loss: 0.9201 - val_mse: 0.9201\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.0969 - mse: 1.0969 - val_loss: 0.9109 - val_mse: 0.9109\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.0836 - mse: 1.0836 - val_loss: 0.9067 - val_mse: 0.9067\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.0697 - mse: 1.0697 - val_loss: 0.9003 - val_mse: 0.9003\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.0594 - mse: 1.0594 - val_loss: 0.8976 - val_mse: 0.8976\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.0502 - mse: 1.0502 - val_loss: 0.8849 - val_mse: 0.8849\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - ETA: 0s - loss: 1.0384 - mse: 1.038 - 0s 3ms/step - loss: 1.0391 - mse: 1.0391 - val_loss: 0.8855 - val_mse: 0.8855\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.0347 - mse: 1.0347 - val_loss: 0.8722 - val_mse: 0.8722\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.0290 - mse: 1.0290 - val_loss: 0.8704 - val_mse: 0.8704\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.0199 - mse: 1.0199 - val_loss: 0.8671 - val_mse: 0.8671\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.0056 - mse: 1.0056 - val_loss: 0.8921 - val_mse: 0.8921\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.0015 - mse: 1.0015 - val_loss: 0.8590 - val_mse: 0.8590\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.9984 - mse: 0.9984 - val_loss: 0.8692 - val_mse: 0.8692\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.9894 - mse: 0.9894 - val_loss: 0.8670 - val_mse: 0.8670\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.9821 - mse: 0.9821 - val_loss: 0.8557 - val_mse: 0.8557\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9757 - mse: 0.9757 - val_loss: 0.8614 - val_mse: 0.8614\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9725 - mse: 0.9725 - val_loss: 0.8617 - val_mse: 0.8617\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9661 - mse: 0.9661 - val_loss: 0.8553 - val_mse: 0.8553\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9593 - mse: 0.9593 - val_loss: 0.8475 - val_mse: 0.8475\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9609 - mse: 0.9609 - val_loss: 0.8533 - val_mse: 0.8533\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9483 - mse: 0.9483 - val_loss: 0.8333 - val_mse: 0.8333\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9426 - mse: 0.9426 - val_loss: 0.8457 - val_mse: 0.8457\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.9378 - mse: 0.9378 - val_loss: 0.8499 - val_mse: 0.8499\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9331 - mse: 0.9331 - val_loss: 0.8229 - val_mse: 0.8229\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9264 - mse: 0.9264 - val_loss: 0.8317 - val_mse: 0.8317\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9224 - mse: 0.9224 - val_loss: 0.8384 - val_mse: 0.8384\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9175 - mse: 0.9175 - val_loss: 0.8222 - val_mse: 0.8222\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9111 - mse: 0.9111 - val_loss: 0.8169 - val_mse: 0.8169\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9066 - mse: 0.9066 - val_loss: 0.8206 - val_mse: 0.8206\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9061 - mse: 0.9061 - val_loss: 0.8533 - val_mse: 0.8533\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9011 - mse: 0.9011 - val_loss: 0.8043 - val_mse: 0.8043\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9009 - mse: 0.9009 - val_loss: 0.7947 - val_mse: 0.7947\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8883 - mse: 0.8883 - val_loss: 0.7995 - val_mse: 0.7995\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8818 - mse: 0.8818 - val_loss: 0.8090 - val_mse: 0.8090\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8797 - mse: 0.8797 - val_loss: 0.7827 - val_mse: 0.7827\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.8787 - mse: 0.8787 - val_loss: 0.8029 - val_mse: 0.8029\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8676 - mse: 0.8676 - val_loss: 0.7930 - val_mse: 0.7930\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8639 - mse: 0.8639 - val_loss: 0.7766 - val_mse: 0.7766\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8561 - mse: 0.8561 - val_loss: 0.7826 - val_mse: 0.7826\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.8639 - mse: 0.8639 - val_loss: 0.7715 - val_mse: 0.7715\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8536 - mse: 0.8536 - val_loss: 0.7646 - val_mse: 0.7646\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8514 - mse: 0.8514 - val_loss: 0.7579 - val_mse: 0.7579\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.8352 - mse: 0.8352 - val_loss: 0.7626 - val_mse: 0.7626\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8336 - mse: 0.8336 - val_loss: 0.7766 - val_mse: 0.7766\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8348 - mse: 0.8348 - val_loss: 0.7468 - val_mse: 0.7468\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.8146 - mse: 0.8146 - val_loss: 0.7818 - val_mse: 0.7818\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8146 - mse: 0.8146 - val_loss: 0.7393 - val_mse: 0.7393\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8113 - mse: 0.8113 - val_loss: 0.7434 - val_mse: 0.7434\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8080 - mse: 0.8080 - val_loss: 0.7402 - val_mse: 0.7402\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8019 - mse: 0.8019 - val_loss: 0.7426 - val_mse: 0.7426\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7987 - mse: 0.7987 - val_loss: 0.7293 - val_mse: 0.7293\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7925 - mse: 0.7925 - val_loss: 0.7306 - val_mse: 0.7306\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7847 - mse: 0.7847 - val_loss: 0.7256 - val_mse: 0.7256\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7815 - mse: 0.7815 - val_loss: 0.7179 - val_mse: 0.7179\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7803 - mse: 0.7803 - val_loss: 0.7119 - val_mse: 0.7119\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7707 - mse: 0.7707 - val_loss: 0.7072 - val_mse: 0.7072\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7690 - mse: 0.7690 - val_loss: 0.7031 - val_mse: 0.7031\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7607 - mse: 0.7607 - val_loss: 0.7154 - val_mse: 0.7154\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7591 - mse: 0.7591 - val_loss: 0.7050 - val_mse: 0.7050\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7526 - mse: 0.7526 - val_loss: 0.7011 - val_mse: 0.7011\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.7546 - mse: 0.7546 - val_loss: 0.6999 - val_mse: 0.6999\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7457 - mse: 0.7457 - val_loss: 0.6844 - val_mse: 0.6844\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7458 - mse: 0.7458 - val_loss: 0.6820 - val_mse: 0.6820\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7370 - mse: 0.7370 - val_loss: 0.6802 - val_mse: 0.6802\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7273 - mse: 0.7273 - val_loss: 0.6765 - val_mse: 0.6765\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7209 - mse: 0.7209 - val_loss: 0.6784 - val_mse: 0.6784\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7241 - mse: 0.7241 - val_loss: 0.6706 - val_mse: 0.6706\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7170 - mse: 0.7170 - val_loss: 0.6842 - val_mse: 0.6842\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7185 - mse: 0.7185 - val_loss: 0.6802 - val_mse: 0.6802\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7080 - mse: 0.7080 - val_loss: 0.6602 - val_mse: 0.6602\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7000 - mse: 0.7000 - val_loss: 0.6623 - val_mse: 0.6623\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6990 - mse: 0.6990 - val_loss: 0.6533 - val_mse: 0.6533\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6904 - mse: 0.6904 - val_loss: 0.6519 - val_mse: 0.6519\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6914 - mse: 0.6914 - val_loss: 0.6478 - val_mse: 0.6478\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6889 - mse: 0.6889 - val_loss: 0.6433 - val_mse: 0.6433\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6905 - mse: 0.6905 - val_loss: 0.6461 - val_mse: 0.6461\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6704 - mse: 0.6704 - val_loss: 0.6420 - val_mse: 0.6420\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6728 - mse: 0.6728 - val_loss: 0.6371 - val_mse: 0.6371\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6637 - mse: 0.6637 - val_loss: 0.6344 - val_mse: 0.6344\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6592 - mse: 0.6592 - val_loss: 0.6349 - val_mse: 0.6349\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6545 - mse: 0.6545 - val_loss: 0.6337 - val_mse: 0.6337\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6524 - mse: 0.6524 - val_loss: 0.6375 - val_mse: 0.6375\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6450 - mse: 0.6450 - val_loss: 0.6242 - val_mse: 0.6242\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.6143 - val_mse: 0.6143\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6373 - mse: 0.6373 - val_loss: 0.6098 - val_mse: 0.6098\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6450 - mse: 0.6450 - val_loss: 0.6101 - val_mse: 0.6101\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6278 - mse: 0.6278 - val_loss: 0.6028 - val_mse: 0.6028\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6284 - mse: 0.6284 - val_loss: 0.6014 - val_mse: 0.6014\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6205 - mse: 0.6205 - val_loss: 0.5949 - val_mse: 0.5949\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6130 - mse: 0.6130 - val_loss: 0.5959 - val_mse: 0.5959\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6092 - mse: 0.6092 - val_loss: 0.5956 - val_mse: 0.5956\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6114 - mse: 0.6114 - val_loss: 0.5854 - val_mse: 0.5854\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6009 - mse: 0.6009 - val_loss: 0.5830 - val_mse: 0.5830\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5933 - mse: 0.5933 - val_loss: 0.5778 - val_mse: 0.5778\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.5858 - mse: 0.585 - 0s 4ms/step - loss: 0.5832 - mse: 0.5832 - val_loss: 0.5775 - val_mse: 0.5775\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5813 - mse: 0.5813 - val_loss: 0.5670 - val_mse: 0.5670\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5683 - mse: 0.5683 - val_loss: 0.5758 - val_mse: 0.5758\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5669 - mse: 0.5669 - val_loss: 0.5625 - val_mse: 0.5625\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5643 - mse: 0.5643 - val_loss: 0.5530 - val_mse: 0.5530\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5508 - mse: 0.5508 - val_loss: 0.5520 - val_mse: 0.5520\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5445 - mse: 0.5445 - val_loss: 0.5452 - val_mse: 0.5452\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5376 - mse: 0.5376 - val_loss: 0.5475 - val_mse: 0.5475\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5322 - mse: 0.5322 - val_loss: 0.5407 - val_mse: 0.5407\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5279 - mse: 0.5279 - val_loss: 0.5326 - val_mse: 0.5326\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5170 - mse: 0.5170 - val_loss: 0.5292 - val_mse: 0.5292\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4993 - mse: 0.4993 - val_loss: 0.5302 - val_mse: 0.5302\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5013 - mse: 0.5013 - val_loss: 0.5207 - val_mse: 0.5207\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4922 - mse: 0.4922 - val_loss: 0.5202 - val_mse: 0.5202\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4896 - mse: 0.4896 - val_loss: 0.5149 - val_mse: 0.5149\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4820 - mse: 0.4820 - val_loss: 0.5117 - val_mse: 0.5117\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4818 - mse: 0.4818 - val_loss: 0.5115 - val_mse: 0.5115\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4768 - mse: 0.4768 - val_loss: 0.5085 - val_mse: 0.5085\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4769 - mse: 0.4769 - val_loss: 0.5155 - val_mse: 0.5155\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4807 - mse: 0.4807 - val_loss: 0.5142 - val_mse: 0.5142\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4681 - mse: 0.4681 - val_loss: 0.5108 - val_mse: 0.5108\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4636 - mse: 0.4636 - val_loss: 0.5118 - val_mse: 0.5118\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4670 - mse: 0.4670 - val_loss: 0.5034 - val_mse: 0.5034\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.4588 - val_loss: 0.5008 - val_mse: 0.5008\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4593 - mse: 0.4593 - val_loss: 0.5006 - val_mse: 0.5006\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4558 - mse: 0.4558 - val_loss: 0.5027 - val_mse: 0.5027\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4567 - mse: 0.4567 - val_loss: 0.4989 - val_mse: 0.4989\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4563 - mse: 0.4563 - val_loss: 0.5001 - val_mse: 0.5001\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4588 - mse: 0.4588 - val_loss: 0.4981 - val_mse: 0.4981\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4511 - mse: 0.4511 - val_loss: 0.5016 - val_mse: 0.5016\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4505 - mse: 0.4505 - val_loss: 0.5001 - val_mse: 0.5001\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4549 - mse: 0.4549 - val_loss: 0.4912 - val_mse: 0.4912\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4506 - mse: 0.4506 - val_loss: 0.4906 - val_mse: 0.4906\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4476 - mse: 0.4476 - val_loss: 0.4926 - val_mse: 0.4926\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4475 - mse: 0.4475 - val_loss: 0.4885 - val_mse: 0.4885\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4501 - mse: 0.4501 - val_loss: 0.4907 - val_mse: 0.4907\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4554 - mse: 0.4554 - val_loss: 0.5189 - val_mse: 0.5189\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4588 - mse: 0.4588 - val_loss: 0.4866 - val_mse: 0.4866\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4462 - mse: 0.4462 - val_loss: 0.4859 - val_mse: 0.4859\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4474 - mse: 0.4474 - val_loss: 0.4879 - val_mse: 0.4879\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4411 - mse: 0.4411 - val_loss: 0.4861 - val_mse: 0.4861\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4424 - mse: 0.4424 - val_loss: 0.4865 - val_mse: 0.4865\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4428 - mse: 0.4428 - val_loss: 0.4783 - val_mse: 0.4783\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4463 - mse: 0.4463 - val_loss: 0.5045 - val_mse: 0.5045\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4404 - mse: 0.4404 - val_loss: 0.4875 - val_mse: 0.4875\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4423 - mse: 0.4423 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4427 - mse: 0.4427 - val_loss: 0.4800 - val_mse: 0.4800\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4415 - mse: 0.4415 - val_loss: 0.4817 - val_mse: 0.4817\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4421 - mse: 0.4421 - val_loss: 0.4868 - val_mse: 0.4868\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4355 - mse: 0.4355 - val_loss: 0.4869 - val_mse: 0.4869\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"mean_squared_error\",\n",
    "           optimizer=\"adam\",\n",
    "           metrics=[\"mse\"])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "model_1 = nn.fit(X,\n",
    "                 y,\n",
    "                 validation_split=0.3,\n",
    "                 epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the train and test loss function\n",
    "plt.plot(model_1.history[\"loss\"])\n",
    "plt.title(\"Loss function - 1 hidden layer\")\n",
    "plt.legend([\"Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = 11\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 = 4\n",
    "\n",
    "\n",
    "nn = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1,\n",
    "             input_dim=number_input_features,\n",
    "             activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2,\n",
    "             activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(Dense(units=1,\n",
    "             activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 1s 5ms/step - loss: 214.3102 - mse: 214.3102 - val_loss: 105.8827 - val_mse: 105.8827\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 40.9461 - mse: 40.9461 - val_loss: 6.2045 - val_mse: 6.2045\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4.8121 - mse: 4.8121 - val_loss: 5.3304 - val_mse: 5.3304\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 3.2309 - mse: 3.2309 - val_loss: 3.7071 - val_mse: 3.7071\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.5125 - mse: 2.5125 - val_loss: 3.0226 - val_mse: 3.0226\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2.0029 - mse: 2.0029 - val_loss: 2.2419 - val_mse: 2.2419\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 1.6460 - mse: 1.6460 - val_loss: 1.8723 - val_mse: 1.8723\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1.3962 - mse: 1.3962 - val_loss: 1.5550 - val_mse: 1.5550\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.2279 - mse: 1.2279 - val_loss: 1.2883 - val_mse: 1.2883\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.1095 - mse: 1.1095 - val_loss: 1.1385 - val_mse: 1.1385\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1.0226 - mse: 1.0226 - val_loss: 1.0478 - val_mse: 1.0478\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9724 - mse: 0.9724 - val_loss: 0.9480 - val_mse: 0.9480\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.9307 - mse: 0.9307 - val_loss: 0.8999 - val_mse: 0.8999\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.8982 - mse: 0.8982 - val_loss: 0.8755 - val_mse: 0.8755\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.8665 - mse: 0.8665 - val_loss: 0.8220 - val_mse: 0.8220\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.8590 - mse: 0.8590 - val_loss: 0.7977 - val_mse: 0.7977\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.8399 - mse: 0.8399 - val_loss: 0.7798 - val_mse: 0.7798\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.8237 - mse: 0.8237 - val_loss: 0.7799 - val_mse: 0.7799\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.8133 - mse: 0.8133 - val_loss: 0.7576 - val_mse: 0.7576\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.7956 - mse: 0.7956 - val_loss: 0.7348 - val_mse: 0.7348\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.7820 - mse: 0.7820 - val_loss: 0.7369 - val_mse: 0.7369\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7802 - mse: 0.7802 - val_loss: 0.7257 - val_mse: 0.7257\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7683 - mse: 0.7683 - val_loss: 0.6964 - val_mse: 0.6964\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7466 - mse: 0.7466 - val_loss: 0.6816 - val_mse: 0.6816\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7167 - mse: 0.7167 - val_loss: 0.6823 - val_mse: 0.6823\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.7060 - mse: 0.7060 - val_loss: 0.6605 - val_mse: 0.6605\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6867 - mse: 0.6867 - val_loss: 0.6457 - val_mse: 0.6457\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6749 - mse: 0.6749 - val_loss: 0.6437 - val_mse: 0.6437\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6547 - mse: 0.6547 - val_loss: 0.6272 - val_mse: 0.6272\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6527 - mse: 0.6527 - val_loss: 0.6213 - val_mse: 0.6213\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6329 - mse: 0.6329 - val_loss: 0.6258 - val_mse: 0.6258\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6053 - mse: 0.6053 - val_loss: 0.6013 - val_mse: 0.6013\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5997 - mse: 0.5997 - val_loss: 0.6048 - val_mse: 0.6048\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5836 - mse: 0.5836 - val_loss: 0.5942 - val_mse: 0.5942\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5691 - mse: 0.5691 - val_loss: 0.5843 - val_mse: 0.5843\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5644 - mse: 0.5644 - val_loss: 0.5706 - val_mse: 0.5706\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5615 - mse: 0.5615 - val_loss: 0.5876 - val_mse: 0.5876\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5446 - mse: 0.5446 - val_loss: 0.5753 - val_mse: 0.5753\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5354 - mse: 0.5354 - val_loss: 0.5528 - val_mse: 0.5528\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5180 - mse: 0.5180 - val_loss: 0.5479 - val_mse: 0.5479\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5118 - mse: 0.5118 - val_loss: 0.5525 - val_mse: 0.5525\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5058 - mse: 0.5058 - val_loss: 0.5394 - val_mse: 0.5394\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4977 - mse: 0.4977 - val_loss: 0.5362 - val_mse: 0.5362\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4930 - mse: 0.4930 - val_loss: 0.5329 - val_mse: 0.5329\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4863 - mse: 0.4863 - val_loss: 0.5305 - val_mse: 0.5305\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4851 - mse: 0.4851 - val_loss: 0.5243 - val_mse: 0.5243\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4785 - mse: 0.4785 - val_loss: 0.5226 - val_mse: 0.5226\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4792 - mse: 0.4792 - val_loss: 0.5234 - val_mse: 0.5234\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4739 - mse: 0.4739 - val_loss: 0.5167 - val_mse: 0.5167\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4672 - mse: 0.4672 - val_loss: 0.5175 - val_mse: 0.5175\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4644 - mse: 0.4644 - val_loss: 0.5153 - val_mse: 0.5153\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4628 - mse: 0.4628 - val_loss: 0.5083 - val_mse: 0.5083\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4620 - mse: 0.4620 - val_loss: 0.5051 - val_mse: 0.5051\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4607 - mse: 0.4607 - val_loss: 0.5046 - val_mse: 0.5046\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.4586 - val_loss: 0.5050 - val_mse: 0.5050\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4562 - mse: 0.4562 - val_loss: 0.4986 - val_mse: 0.4986\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4609 - mse: 0.4609 - val_loss: 0.4961 - val_mse: 0.4961\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4549 - mse: 0.4549 - val_loss: 0.5028 - val_mse: 0.5028\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4562 - mse: 0.4562 - val_loss: 0.4945 - val_mse: 0.4945\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4550 - mse: 0.4550 - val_loss: 0.4950 - val_mse: 0.4950\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4530 - mse: 0.4530 - val_loss: 0.4921 - val_mse: 0.4921\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4523 - mse: 0.4523 - val_loss: 0.4899 - val_mse: 0.4899\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4501 - mse: 0.4501 - val_loss: 0.4956 - val_mse: 0.4956\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4516 - mse: 0.4516 - val_loss: 0.4903 - val_mse: 0.4903\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4482 - mse: 0.4482 - val_loss: 0.4942 - val_mse: 0.4942\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4518 - mse: 0.4518 - val_loss: 0.5020 - val_mse: 0.5020\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4577 - mse: 0.4577 - val_loss: 0.4875 - val_mse: 0.4875\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4485 - mse: 0.4485 - val_loss: 0.4846 - val_mse: 0.4846\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.4466 - mse: 0.4466 - val_loss: 0.4853 - val_mse: 0.4853\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4442 - mse: 0.4442 - val_loss: 0.4966 - val_mse: 0.4966\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4555 - mse: 0.4555 - val_loss: 0.4868 - val_mse: 0.4868\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4499 - mse: 0.4499 - val_loss: 0.4825 - val_mse: 0.4825\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4455 - mse: 0.4455 - val_loss: 0.4777 - val_mse: 0.4777\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.4504 - mse: 0.4504 - val_loss: 0.4866 - val_mse: 0.4866\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4465 - mse: 0.4465 - val_loss: 0.4845 - val_mse: 0.4845\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4562 - mse: 0.4562 - val_loss: 0.4867 - val_mse: 0.4867\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4454 - mse: 0.4454 - val_loss: 0.4828 - val_mse: 0.4828\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4469 - mse: 0.4469 - val_loss: 0.4821 - val_mse: 0.4821\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4439 - mse: 0.4439 - val_loss: 0.4786 - val_mse: 0.4786\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4458 - mse: 0.4458 - val_loss: 0.4784 - val_mse: 0.4784\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4417 - mse: 0.4417 - val_loss: 0.4779 - val_mse: 0.4779\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4418 - mse: 0.4418 - val_loss: 0.4778 - val_mse: 0.4778\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4516 - mse: 0.4516 - val_loss: 0.4807 - val_mse: 0.4807\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4416 - mse: 0.4416 - val_loss: 0.4806 - val_mse: 0.4806\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4422 - mse: 0.4422 - val_loss: 0.4717 - val_mse: 0.4717\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4486 - mse: 0.4486 - val_loss: 0.4876 - val_mse: 0.4876\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4537 - mse: 0.4537 - val_loss: 0.4991 - val_mse: 0.4991\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4455 - mse: 0.4455 - val_loss: 0.4763 - val_mse: 0.4763\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4438 - mse: 0.4438 - val_loss: 0.4807 - val_mse: 0.4807\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4440 - mse: 0.4440 - val_loss: 0.4741 - val_mse: 0.4741\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4771 - val_mse: 0.4771\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4419 - mse: 0.4419 - val_loss: 0.4767 - val_mse: 0.4767\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4423 - mse: 0.4423 - val_loss: 0.4679 - val_mse: 0.4679\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4398 - mse: 0.4398 - val_loss: 0.4706 - val_mse: 0.4706\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4443 - mse: 0.4443 - val_loss: 0.4883 - val_mse: 0.4883\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4376 - mse: 0.4376 - val_loss: 0.4713 - val_mse: 0.4713\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4445 - mse: 0.4445 - val_loss: 0.4692 - val_mse: 0.4692\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4413 - mse: 0.4413 - val_loss: 0.4685 - val_mse: 0.4685\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4452 - mse: 0.4452 - val_loss: 0.4671 - val_mse: 0.4671\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4395 - mse: 0.4395 - val_loss: 0.4666 - val_mse: 0.4666\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4402 - mse: 0.4402 - val_loss: 0.4665 - val_mse: 0.4665\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4369 - mse: 0.4369 - val_loss: 0.4730 - val_mse: 0.4730\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4473 - mse: 0.4473 - val_loss: 0.4671 - val_mse: 0.4671\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4311 - mse: 0.4311 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4353 - mse: 0.4353 - val_loss: 0.4759 - val_mse: 0.4759\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4392 - mse: 0.4392 - val_loss: 0.4724 - val_mse: 0.4724\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4351 - mse: 0.4351 - val_loss: 0.4634 - val_mse: 0.4634\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4345 - mse: 0.4345 - val_loss: 0.4703 - val_mse: 0.4703\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4392 - mse: 0.4392 - val_loss: 0.4814 - val_mse: 0.4814\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4759 - val_mse: 0.4759\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4481 - mse: 0.4481 - val_loss: 0.4699 - val_mse: 0.4699\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4335 - mse: 0.4335 - val_loss: 0.4672 - val_mse: 0.4672\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4353 - mse: 0.4353 - val_loss: 0.4570 - val_mse: 0.4570\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4357 - mse: 0.4357 - val_loss: 0.4711 - val_mse: 0.4711\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4371 - mse: 0.4371 - val_loss: 0.4769 - val_mse: 0.4769\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4486 - mse: 0.4486 - val_loss: 0.4919 - val_mse: 0.4919\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4586 - mse: 0.4586 - val_loss: 0.5087 - val_mse: 0.5087\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4387 - mse: 0.4387 - val_loss: 0.4639 - val_mse: 0.4639\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4347 - mse: 0.4347 - val_loss: 0.4762 - val_mse: 0.4762\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4393 - mse: 0.4393 - val_loss: 0.4607 - val_mse: 0.4607\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4340 - mse: 0.4340 - val_loss: 0.4621 - val_mse: 0.4621\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4347 - mse: 0.4347 - val_loss: 0.4615 - val_mse: 0.4615\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4320 - mse: 0.4320 - val_loss: 0.4586 - val_mse: 0.4586\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4477 - mse: 0.4477 - val_loss: 0.4765 - val_mse: 0.4765\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4326 - mse: 0.4326 - val_loss: 0.4648 - val_mse: 0.4648\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4340 - mse: 0.4340 - val_loss: 0.4795 - val_mse: 0.4795\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4382 - mse: 0.4382 - val_loss: 0.5166 - val_mse: 0.5166\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4331 - mse: 0.4331 - val_loss: 0.4744 - val_mse: 0.4744\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4346 - mse: 0.4346 - val_loss: 0.4570 - val_mse: 0.4570\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4301 - mse: 0.4301 - val_loss: 0.4616 - val_mse: 0.4616\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4329 - mse: 0.4329 - val_loss: 0.4563 - val_mse: 0.4563\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4395 - mse: 0.4395 - val_loss: 0.4639 - val_mse: 0.4639\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4462 - mse: 0.4462 - val_loss: 0.4716 - val_mse: 0.4716\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4390 - mse: 0.4390 - val_loss: 0.4606 - val_mse: 0.4606\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4521 - mse: 0.4521 - val_loss: 0.4795 - val_mse: 0.4795\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4433 - mse: 0.4433 - val_loss: 0.4600 - val_mse: 0.4600\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4339 - mse: 0.4339 - val_loss: 0.4648 - val_mse: 0.4648\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4380 - mse: 0.4380 - val_loss: 0.4624 - val_mse: 0.4624\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4302 - mse: 0.4302 - val_loss: 0.4605 - val_mse: 0.4605\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4303 - mse: 0.4303 - val_loss: 0.4577 - val_mse: 0.4577\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4314 - mse: 0.4314 - val_loss: 0.4558 - val_mse: 0.4558\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4312 - mse: 0.4312 - val_loss: 0.4587 - val_mse: 0.4587\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4305 - mse: 0.4305 - val_loss: 0.4492 - val_mse: 0.4492\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4365 - mse: 0.4365 - val_loss: 0.4612 - val_mse: 0.4612\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4305 - mse: 0.4305 - val_loss: 0.4549 - val_mse: 0.4549\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4319 - mse: 0.4319 - val_loss: 0.4659 - val_mse: 0.4659\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4442 - mse: 0.4442 - val_loss: 0.4601 - val_mse: 0.4601\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4262 - mse: 0.4262 - val_loss: 0.4924 - val_mse: 0.4924\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4338 - mse: 0.4338 - val_loss: 0.4688 - val_mse: 0.4688\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4359 - mse: 0.4359 - val_loss: 0.4560 - val_mse: 0.4560\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4355 - mse: 0.4355 - val_loss: 0.4583 - val_mse: 0.4583\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4351 - mse: 0.4351 - val_loss: 0.4732 - val_mse: 0.4732\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4328 - mse: 0.4328 - val_loss: 0.4584 - val_mse: 0.4584\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4288 - mse: 0.4288 - val_loss: 0.4914 - val_mse: 0.4914\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4312 - mse: 0.4312 - val_loss: 0.4795 - val_mse: 0.4795\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4307 - mse: 0.4307 - val_loss: 0.4823 - val_mse: 0.4823\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4462 - mse: 0.4462 - val_loss: 0.4646 - val_mse: 0.4646\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4301 - mse: 0.4301 - val_loss: 0.4705 - val_mse: 0.4705\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4321 - mse: 0.4321 - val_loss: 0.4994 - val_mse: 0.4994\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4300 - mse: 0.4300 - val_loss: 0.4526 - val_mse: 0.4526\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4306 - mse: 0.4306 - val_loss: 0.4585 - val_mse: 0.4585\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4337 - mse: 0.4337 - val_loss: 0.4959 - val_mse: 0.4959\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4477 - mse: 0.4477 - val_loss: 0.5222 - val_mse: 0.5222\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4353 - mse: 0.4353 - val_loss: 0.4579 - val_mse: 0.4579\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4331 - mse: 0.4331 - val_loss: 0.4970 - val_mse: 0.4970\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4313 - mse: 0.4313 - val_loss: 0.4857 - val_mse: 0.4857\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4290 - mse: 0.4290 - val_loss: 0.4710 - val_mse: 0.4710\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4310 - mse: 0.4310 - val_loss: 0.4553 - val_mse: 0.4553\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4308 - mse: 0.4308 - val_loss: 0.4565 - val_mse: 0.4565\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4369 - mse: 0.4369 - val_loss: 0.5377 - val_mse: 0.5377\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4466 - mse: 0.4466 - val_loss: 0.4479 - val_mse: 0.4479\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4317 - mse: 0.4317 - val_loss: 0.4524 - val_mse: 0.4524\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4257 - mse: 0.4257 - val_loss: 0.4532 - val_mse: 0.4532\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4333 - mse: 0.4333 - val_loss: 0.4599 - val_mse: 0.4599\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4309 - mse: 0.4309 - val_loss: 0.4580 - val_mse: 0.4580\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4414 - mse: 0.4414 - val_loss: 0.4678 - val_mse: 0.4678\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4259 - mse: 0.4259 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4291 - mse: 0.4291 - val_loss: 0.4500 - val_mse: 0.4500\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4328 - mse: 0.4328 - val_loss: 0.4652 - val_mse: 0.4652\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4396 - mse: 0.4396 - val_loss: 0.4508 - val_mse: 0.4508\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4293 - mse: 0.4293 - val_loss: 0.5058 - val_mse: 0.5058\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4305 - mse: 0.4305 - val_loss: 0.4716 - val_mse: 0.4716\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4355 - mse: 0.4355 - val_loss: 0.4483 - val_mse: 0.4483\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4271 - mse: 0.4271 - val_loss: 0.4660 - val_mse: 0.4660\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4273 - mse: 0.4273 - val_loss: 0.4653 - val_mse: 0.4653\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4368 - mse: 0.4368 - val_loss: 0.5126 - val_mse: 0.5126\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4297 - mse: 0.4297 - val_loss: 0.4557 - val_mse: 0.4557\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4388 - mse: 0.4388 - val_loss: 0.4701 - val_mse: 0.4701\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4279 - mse: 0.4279 - val_loss: 0.4602 - val_mse: 0.4602\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4324 - mse: 0.432 - 0s 5ms/step - loss: 0.4255 - mse: 0.4255 - val_loss: 0.4492 - val_mse: 0.4492\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4369 - mse: 0.4369 - val_loss: 0.4458 - val_mse: 0.4458\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4294 - mse: 0.4294 - val_loss: 0.4649 - val_mse: 0.4649\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4405 - mse: 0.4405 - val_loss: 0.4472 - val_mse: 0.4472\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4441 - mse: 0.4441 - val_loss: 0.4701 - val_mse: 0.4701\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4314 - mse: 0.4314 - val_loss: 0.4639 - val_mse: 0.4639\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4280 - mse: 0.4280 - val_loss: 0.4503 - val_mse: 0.4503\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4258 - mse: 0.4258 - val_loss: 0.4481 - val_mse: 0.4481\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4294 - mse: 0.4294 - val_loss: 0.4487 - val_mse: 0.4487\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.4255 - mse: 0.4255 - val_loss: 0.4528 - val_mse: 0.4528\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4218 - mse: 0.4218 - val_loss: 0.4554 - val_mse: 0.4554\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "nn.compile(loss=\"mean_squared_error\",\n",
    "           optimizer=\"adam\",\n",
    "           metrics=[\"mse\"])\n",
    "\n",
    "# Fit the model\n",
    "model_2 = nn.fit(X,\n",
    "                 y,\n",
    "                 validation_split=0.3,\n",
    "                 epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_1.history[\"loss\"])\n",
    "plt.plot(model_2.history[\"loss\"])\n",
    "plt.title(\"Loss function - Training\")\n",
    "plt.legend([\"1 hidden layer\", \"2 hidden layer\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train vs test for deep net\n",
    "plt.plot(model_2.history[\"loss\"])\n",
    "plt.plot(model_1.history[\"val_loss\"])\n",
    "plt.title(\"Loss function - Training vs Validation - 2 hidden layer\")\n",
    "plt.legend([\"Train\", \"Test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
