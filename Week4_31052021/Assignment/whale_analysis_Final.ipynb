{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  A Whale off the Port(folio)\n",
    " ---\n",
    "\n",
    " In this assignment, you'll get to use what you've learned this week to evaluate the performance among various algorithmic, hedge, and mutual fund portfolios and compare them against the S&P TSX 60 Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps. After cleaning, combine all DataFrames into a single DataFrame.\n",
    "\n",
    "Files:\n",
    "\n",
    "* `whale_returns.csv`: Contains returns of some famous \"whale\" investors' portfolios.\n",
    "\n",
    "* `algo_returns.csv`: Contains returns from the in-house trading algorithms from Harold's company.\n",
    "\n",
    "* `sp_tsx_history.csv`: Contains historical closing prices of the S&P TSX 60 Index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale Returns\n",
    "\n",
    "Read the Whale Portfolio daily returns and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whale = r'C:\\Users\\TribThapa\\Desktop\\Thapa\\ResearchFellow\\Courses\\FinTech_Bootcamp_MonashUni2021\\monu-mel-virt-fin-pt-05-2021-u-c\\Homework\\Week 4\\Instructions\\Starter_Code\\Resources\\whale_returns.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading whale returns\n",
    "whale_df = pd.read_csv(whale, infer_datetime_format=True, parse_dates=True, index_col='Date')\n",
    "whale_df.head()\n",
    "whale_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "whale_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls and sort index order\n",
    "whale_drop_df = whale_df.dropna()\n",
    "whale_drop_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Daily Returns\n",
    "\n",
    "Read the algorithmic daily returns and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading algorithmic returns into pandas dataframe\n",
    "algo = r'C:\\Users\\TribThapa\\Desktop\\Thapa\\ResearchFellow\\Courses\\FinTech_Bootcamp_MonashUni2021\\monu-mel-virt-fin-pt-05-2021-u-c\\Homework\\Week 4\\Instructions\\Starter_Code\\Resources\\algo_returns.csv'\n",
    "\n",
    "algo_df = pd.read_csv(algo, infer_datetime_format=True, parse_dates=True, index_col='Date')\n",
    "algo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "algo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls and sort index\n",
    "algo_drop_df = algo_df.dropna()\n",
    "algo_drop_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P TSX 60 Returns\n",
    "\n",
    "Read the S&P TSX 60 historic closing prices and create a new daily returns DataFrame from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading S&P TSX 60 Closing Prices\n",
    "SP500 = r'C:\\Users\\TribThapa\\Desktop\\Thapa\\ResearchFellow\\Courses\\FinTech_Bootcamp_MonashUni2021\\monu-mel-virt-fin-pt-05-2021-u-c\\Homework\\Week 4\\Instructions\\Starter_Code\\Resources\\sp_tsx_history.csv'\n",
    "\n",
    "SP500_df = pd.read_csv(SP500, infer_datetime_format=True, parse_dates=True, index_col='Date')\n",
    "SP500_df.head()\n",
    "#SP500_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data Types\n",
    "SP500_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Data Types: remove $ sign\n",
    "SP500_df['Close'] = SP500_df['Close'].str.replace(\"$\", \"\")\n",
    "SP500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Data Types: remove comma\n",
    "SP500_df.replace(\",\", \"\", regex=True, inplace=True)\n",
    "SP500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dtype to float\n",
    "SP500_df['Close'] = SP500_df['Close'].astype('float')\n",
    "SP500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dtype\n",
    "SP500_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns\n",
    "daily_returns = SP500_df['Close'].pct_change()\n",
    "daily_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "SP500_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename `Close` Column to be specific to this portfolio.\n",
    "SP500_df = SP500_df.rename(columns={'Close' : 'SP500_Close'})\n",
    "SP500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_df['SP500'] = daily_returns\n",
    "SP500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 'Close' column\n",
    "SP500_df.drop(columns=['SP500_Close'], inplace=True)\n",
    "SP500_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Whale, Algorithmic, and S&P TSX 60 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Whale Returns, Algorithmic Returns, and the S&P TSX 60 Returns into a single DataFrame with columns for each portfolio's returns.\n",
    "combined_df = pd.concat([whale_drop_df, algo_drop_df, SP500_df], axis='columns', join='inner')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Quantitative Analysis\n",
    "\n",
    "In this section, you will calculate and visualize performance and risk metrics for the portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Anlysis\n",
    "\n",
    "#### Calculate and Plot the daily returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily returns of all portfolios\n",
    "combined_df.plot(figsize=(15, 10), xlabel='Year', title='Daily Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate and Plot cumulative returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted returns (equal weighting)\n",
    "soros_returns = combined_df['SOROS FUND MANAGEMENT LLC'] * 0.14\n",
    "paulson_returns = combined_df['PAULSON & CO.INC. '] * 0.14\n",
    "tiger_returns = combined_df['TIGER GLOBAL MANAGEMENT LLC'] * 0.14\n",
    "berkshire_returns = combined_df['BERKSHIRE HATHAWAY INC'] * 0.14\n",
    "algo1_returns = combined_df['Algo 1'] * 0.14\n",
    "algo2_returns = combined_df['Algo 2'] * 0.14\n",
    "SP500_returns = combined_df['SP500'] * 0.14\n",
    "\n",
    "# Calculate cumulative returns of all portfolios\n",
    "cumlative_returns_soros = (1+soros_returns).cumprod()\n",
    "cumlative_returns_paulson = (1+paulson_returns).cumprod()\n",
    "cumlative_returns_tiger = (1+tiger_returns).cumprod()\n",
    "cumlative_returns_berkshire = (1+berkshire_returns).cumprod()\n",
    "cumlative_returns_algo1 = (1+algo1_returns).cumprod()\n",
    "cumlative_returns_algo2 = (1+algo2_returns).cumprod()\n",
    "cumlative_returns_sp500 = (1+SP500_returns).cumprod()\n",
    "\n",
    "# Plot cumulative returns\n",
    "plot1 = cumlative_returns_soros.plot(figsize=(10, 7), color='y', linestyle='dashed', title='Comparing all portfolios with SP500')\n",
    "cumlative_returns_paulson.plot(ax=plot1, color='r', linestyle='dotted', alpha=0.9)\n",
    "cumlative_returns_tiger.plot(ax=plot1, color='g', linestyle='dashdot', alpha=0.8)\n",
    "cumlative_returns_berkshire.plot(ax=plot1, color='b', linestyle='dotted', alpha=0.7)\n",
    "cumlative_returns_algo1.plot(ax=plot1, color='m', linestyle='dotted', alpha=0.6)\n",
    "cumlative_returns_algo2.plot(ax=plot1, color='c', alpha=0.5)\n",
    "cumlative_returns_sp500.plot(ax=plot1, color='black')\n",
    "\n",
    "plot1.legend(['Soros', 'Paulson', 'Tiger', 'Berkshire', 'Algo1', 'Algo2', 'SP500'])\n",
    "plot1.set_xlabel('Year')\n",
    "plot1.set_ylabel('Cumulative returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative approach to get cumulative returns. \n",
    "#Approach above allows you to get a better handle on data but not feasible with large DataFrames.\n",
    "cumlative_returns = (1+combined_df).cumprod()\n",
    "cumlative_returns.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Analysis\n",
    "\n",
    "Determine the _risk_ of each portfolio:\n",
    "\n",
    "1. Create a box plot for each portfolio. \n",
    "2. Calculate the standard deviation for all portfolios.\n",
    "4. Determine which portfolios are riskier than the S&P TSX 60.\n",
    "5. Calculate the Annualized Standard Deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a box plot for each portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot to visually show risk\n",
    "data_to_plot = [combined_df['SOROS FUND MANAGEMENT LLC'], \n",
    "                combined_df['PAULSON & CO.INC. '],\n",
    "                combined_df['TIGER GLOBAL MANAGEMENT LLC'],\n",
    "                combined_df['BERKSHIRE HATHAWAY INC'],\n",
    "                combined_df['Algo 1'],\n",
    "                combined_df['Algo 2'],\n",
    "                combined_df['SP500']]\n",
    "\n",
    "flierprops = dict(marker='o', markerfacecolor='r', markersize=5, markeredgecolor='k')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "box = plt.boxplot(data_to_plot,\n",
    "                  labels =['Soros', 'Paulson', 'Tiger', 'Berkshire', 'Algo1', 'Algo2', 'SP500'],\n",
    "                  flierprops=flierprops,\n",
    "                  showmeans=True)\n",
    "\n",
    "ax.set_title('Daily returns across all portfolios')\n",
    "ax.set_xlabel('Portfolio')\n",
    "ax.set_ylabel('Daily returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily standard deviations of all portfolios\n",
    "soros_std = combined_df['SOROS FUND MANAGEMENT LLC'].std()\n",
    "paulson_std = combined_df['PAULSON & CO.INC. '].std()\n",
    "tiger_std = combined_df['TIGER GLOBAL MANAGEMENT LLC'].std()\n",
    "berkshire_std = combined_df['BERKSHIRE HATHAWAY INC'].std()\n",
    "algo1_std = combined_df['Algo 1'].std()\n",
    "algo2_std = combined_df['Algo 2'].std()\n",
    "\n",
    "#Times std by 100 to make interpretation easier\n",
    "print(f\"Soros' std is {soros_std * 100}\")\n",
    "print(f\"Paulson's std is {paulson_std * 100}\")\n",
    "print(f\"Tiger's std is {tiger_std * 100}\")\n",
    "print(f\"Berkshire's std is {berkshire_std * 100}\")\n",
    "print(f\"Algo1's std is {algo1_std * 100}\")\n",
    "print(f\"Algo2's std is {algo2_std * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which portfolios are riskier than the S&P TSX 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily standard deviation of S&P TSX 60\n",
    "sp500_std = combined_df['SP500'].std()\n",
    "print(f\"SP500's std is {sp500_std}\")\n",
    "\n",
    "# Determine which portfolios are riskier than the S&P TSX 60 using plot\n",
    "std_list = [soros_std, paulson_std, tiger_std, berkshire_std, algo1_std, algo2_std, sp500_std]\n",
    "row_names = ['soros', 'paulson', 'tiger', 'berkshire', 'algo1', 'algo2', 'sp500_std']\n",
    "\n",
    "std_list_df = pd.DataFrame(std_list, row_names)\n",
    "\n",
    "std_list_df.plot(marker='o', color='r', markerfacecolor='blue', xlabel='Portfolio', ylabel='Std dev')\n",
    "\n",
    "print()\n",
    "print(f\"Portfolios 'TIGER', 'BERKSHIRE', and 'ALGO2' have higher variability in their daily returns when compared the SP500 \\n\"\n",
    "      f\"suggesting these portfolios are riskier than S&P TSX 60. \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "soros_std_annl = combined_df['SOROS FUND MANAGEMENT LLC'].std() *np.sqrt(252)\n",
    "paulson_std_annl = combined_df['PAULSON & CO.INC. '].std() *np.sqrt(252)\n",
    "tiger_std_annl = combined_df['TIGER GLOBAL MANAGEMENT LLC'].std() *np.sqrt(252)\n",
    "berkshire_std_annl = combined_df['BERKSHIRE HATHAWAY INC'].std() *np.sqrt(252)\n",
    "algo1_std_annl = combined_df['Algo 1'].std() *np.sqrt(252)\n",
    "algo2_std_annl = combined_df['Algo 2'].std() *np.sqrt(252)\n",
    "sp500_std_annl = combined_df['SP500'].std() *np.sqrt(252)\n",
    "\n",
    "print(f\"Soros' std is {soros_std_annl}\")\n",
    "print(f\"Paulson's std is {paulson_std_annl}\")\n",
    "print(f\"Tiger's std is {tiger_std_annl}\")\n",
    "print(f\"Berkshire's std is {berkshire_std_annl}\")\n",
    "print(f\"Algo1's std is {algo1_std_annl}\")\n",
    "print(f\"Algo2's std is {algo2_std_annl}\")\n",
    "print(f\"SP500's std is {sp500_std_annl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which portfolios are riskier than the S&P TSX 60\n",
    "std_annl_list = [soros_std_annl, paulson_std_annl, tiger_std_annl, berkshire_std_annl, algo1_std_annl, algo2_std_annl, sp500_std_annl]\n",
    "row_names = ['soros', 'paulson', 'tiger', 'berkshire', 'algo1', 'algo2', 'sp500_std']\n",
    "\n",
    "std_annl_list_df = pd.DataFrame(std_annl_list, row_names)\n",
    "std_annl_list_df.head()\n",
    "\n",
    "std_annl_list_df.plot(marker='o', color='r', markerfacecolor='blue', ylabel='Std dev', xlabel='Portfolios', title='Annualised standard deviation')\n",
    "\n",
    "print()\n",
    "print(f\"Portfolios 'TIGER', 'BERKSHIRE', and 'ALGO2' have higher variability in their daily returns when compared the SP500 \\n\"\n",
    "      f\"suggesting these portfolios are riskier than S&P TSX 60. \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics\n",
    "\n",
    "Risk changes over time. Analyze the rolling statistics for Risk and Beta. \n",
    "\n",
    "1. Calculate and plot the rolling standard deviation for all portfolios using a 21-day window.\n",
    "2. Calculate the correlation between each stock to determine which portfolios may mimick the S&P TSX 60.\n",
    "3. Choose one portfolio, then calculate and plot the 60-day rolling beta for it and the S&P TSX 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot rolling `std` for all portfolios with 21-day window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rolling standard deviation for all portfolios using a 21-day window\n",
    "roll_std_soros = combined_df['SOROS FUND MANAGEMENT LLC'].rolling(window=21).std()\n",
    "roll_std_paulson = combined_df['PAULSON & CO.INC. '].rolling(window=21).std()\n",
    "roll_std_tiger = combined_df['TIGER GLOBAL MANAGEMENT LLC'].rolling(window=21).std()\n",
    "roll_std_berkshire = combined_df['BERKSHIRE HATHAWAY INC'].rolling(window=21).std()\n",
    "roll_std_algo1 = combined_df['Algo 1'].rolling(window=21).std()\n",
    "roll_std_algo2 = combined_df['Algo 2'].rolling(window=21).std()\n",
    "roll_std_sp500 = combined_df['SP500'].rolling(window=21).std()\n",
    "\n",
    "# Plot the rolling standard deviation\n",
    "plot3 = roll_std_soros.plot(figsize=(15, 10), title='Rolling 21-day standard deviation', color='y')\n",
    "roll_std_paulson.plot(ax=plot3, color='r', linestyle='dotted', alpha=0.9)\n",
    "roll_std_tiger.plot(ax=plot3, color='g', linestyle='dashdot', alpha=0.8)\n",
    "roll_std_berkshire.plot(ax=plot3, color='b', linestyle='dotted', alpha=0.7)\n",
    "roll_std_algo1.plot(ax=plot3, color='m', linestyle='dotted', alpha=0.6)\n",
    "roll_std_algo2.plot(ax=plot3, color='c', alpha=0.5)\n",
    "roll_std_sp500.plot(ax=plot3, color='k')\n",
    "\n",
    "plot3.legend(['Soros', 'Paulson', 'Tiger', 'Berkshire', 'Algo1', 'Algo2', 'SP500'])\n",
    "plot3.set_xlabel('Year')\n",
    "plot3.set_ylabel('Rolling std dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation\n",
    "correlation = combined_df.corr()\n",
    "correlation\n",
    "\n",
    "# Display the correlation matrix\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "h = plt.axes()\n",
    "sns.heatmap(correlation, vmin=-1, vmax=1, annot=True, cmap=cmap)\n",
    "sns.set(rc={'figure.figsize':(10,7)})\n",
    "h.set_title('Correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Plot Beta for a chosen portfolio and the S&P 60 TSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance of a single portfolio\n",
    "cov_berkshire = combined_df['BERKSHIRE HATHAWAY INC'].rolling(window=20).cov(combined_df['SP500'])\n",
    "\n",
    "# Calculate variance of S&P TSX\n",
    "var_SP500 = combined_df['SP500'].rolling(window=60).var()\n",
    "\n",
    "# Computing beta\n",
    "beta_berkshire = cov_berkshire / var_SP500\n",
    "\n",
    "# Generate plot\n",
    "plot_berkshire_beta = beta_berkshire.plot(figsize=(15,10), color='blue')\n",
    "\n",
    "# Set the legend of the figure\n",
    "plot_berkshire_beta.set_xlabel('Year')\n",
    "plot_berkshire_beta.set_ylabel('Beta value over 60 day-roll')\n",
    "plot_berkshire_beta.figure.savefig('CustomPortFolio_Beta.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance of a single portfolio\n",
    "cov_soros = combined_df['SOROS FUND MANAGEMENT LLC'].cov(combined_df['SP500'])\n",
    "cov_paulson = combined_df['PAULSON & CO.INC. '].cov(combined_df['SP500'])\n",
    "cov_tiger = combined_df['TIGER GLOBAL MANAGEMENT LLC'].cov(combined_df['SP500'])\n",
    "cov_berkshire = combined_df['BERKSHIRE HATHAWAY INC'].cov(combined_df['SP500'])\n",
    "cov_algo1 = combined_df['Algo 1'].cov(combined_df['SP500'])\n",
    "cov_algo2 = combined_df['Algo 2'].cov(combined_df['SP500'])\n",
    "\n",
    "# Calculate variance of S&P TSX\n",
    "var_SP500 = combined_df['SP500'].var()\n",
    "\n",
    "# Computing beta\n",
    "beta_soros = cov_soros / var_SP500\n",
    "beta_paulson = cov_paulson / var_SP500\n",
    "beta_tiger = cov_tiger / var_SP500\n",
    "beta_berkshire = cov_berkshire / var_SP500\n",
    "beta_algo1 = cov_algo1 / var_SP500\n",
    "beta_algo2 = cov_algo2 / var_SP500\n",
    "\n",
    "print(f\"The beta score for Soros is {beta_soros}. \")\n",
    "print(f\"The beta score for Paulson is {beta_paulson}. \")\n",
    "print(f\"The beta score for Tiger is {beta_tiger}. \")\n",
    "print(f\"The beta score for Berkshire is {beta_berkshire}. \")\n",
    "print(f\"The beta score for Algo1 is {beta_algo1}. \")\n",
    "print(f\"The beta score for Algo2 is {beta_algo2}. \")\n",
    "\n",
    "# Plot beta trend\n",
    "beta_list = [beta_soros, beta_paulson, beta_tiger, beta_berkshire, beta_algo1, beta_algo2]\n",
    "row_names = ['soros', 'paulson', 'tiger', 'berkshire', 'algo1', 'algo2']\n",
    "\n",
    "beta_list_df = pd.DataFrame(beta_list, row_names)\n",
    "beta_list_df.head()\n",
    "\n",
    "beta_list_df.plot(marker='o', color='r', markerfacecolor='blue', ylabel='Beta', xlabel='Portfolios', title='Beta values between portfolios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics Challenge: Exponentially Weighted Average \n",
    "\n",
    "An alternative way to calculate a rolling window is to take the exponentially weighted moving average. This is like a moving window average, but it assigns greater importance to more recent observations. Try calculating the [`ewm`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html) with a 21-day half-life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `ewm` to calculate the rolling window\n",
    "roll_stat1 = combined_df.ewm(halflife=21, min_periods=21).mean()\n",
    "roll_stat1.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results to above\n",
    "roll_stat2 = combined_df.rolling(window=21).mean()\n",
    "roll_stat2.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpe Ratios\n",
    "In reality, investment managers and thier institutional investors look at the ratio of return-to-risk, and not just returns alone. After all, if you could invest in one of two portfolios, and each offered the same 10% return, yet one offered lower risk, you'd take that one, right?\n",
    "\n",
    "### Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualized Sharpe Ratios\n",
    "sharpe_ratio = (combined_df.mean()*252) / (combined_df.std()*np.sqrt(252))\n",
    "sharpe_ratio.sort_values(ascending=False)\n",
    "\n",
    "# Visualize the sharpe ratios as a bar plot\n",
    "sharpe_ratio.plot(kind='bar',\n",
    "                  figsize=(10, 7),\n",
    "                  title='Sharpe ratios for each portfolio', \n",
    "                  edgecolor='red', \n",
    "                  color='black',\n",
    "                  ylabel='Sharpe ratio',\n",
    "                  xlabel='Portfolios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine whether the algorithmic strategies outperform both the market (S&P TSX 60) and the whales portfolios.\n",
    "\n",
    "Algo1 outperforms both S&P500 and Whale portfolios. This is determined by the following results:\n",
    "\n",
    " - Cumulative returns of 1.4 i.e, almost a 40% increase when compared to the SP500, and >= 20% increase when compared to whale portfolios. \n",
    " - Relatively low standard deviation (annualised) of 1.9 when compared to SP500 (1.77) and other whale portfolios suggesting less variability in annual daily returns.\n",
    " - Beta of 0.33 suggesting Algo 1 is less volatile than the market.\n",
    " - Sharpe ratio of 1.49 suggesting Algo 1 has the best returns for the relative risk undertaken.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Custom Portfolio\n",
    "\n",
    "In this section, you will build your own portfolio of stocks, calculate the returns, and compare the results to the Whale Portfolios and the S&P TSX 60. \n",
    "\n",
    "1. Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock.\n",
    "2. Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock.\n",
    "3. Join your portfolio returns to the DataFrame that contains all of the portfolio returns.\n",
    "4. Re-run the performance and risk analysis with your portfolio to see how it compares to the others.\n",
    "5. Include correlation analysis to determine which stocks (if any) are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 1st stock\n",
    "ivv = r'C:\\Users\\TribThapa\\Desktop\\Thapa\\ResearchFellow\\Courses\\FinTech_Bootcamp_MonashUni2021\\monu-mel-virt-fin-pt-05-2021-u-c\\MyFinTechHomework\\Week4_31052021\\Assignment\\IVV.csv'\n",
    "vap = r'C:\\Users\\TribThapa\\Desktop\\Thapa\\ResearchFellow\\Courses\\FinTech_Bootcamp_MonashUni2021\\monu-mel-virt-fin-pt-05-2021-u-c\\MyFinTechHomework\\Week4_31052021\\Assignment\\VAP.csv'\n",
    "vso = r'C:\\Users\\TribThapa\\Desktop\\Thapa\\ResearchFellow\\Courses\\FinTech_Bootcamp_MonashUni2021\\monu-mel-virt-fin-pt-05-2021-u-c\\MyFinTechHomework\\Week4_31052021\\Assignment\\VSO.csv'\n",
    "vas = r'C:\\Users\\TribThapa\\Desktop\\Thapa\\ResearchFellow\\Courses\\FinTech_Bootcamp_MonashUni2021\\monu-mel-virt-fin-pt-05-2021-u-c\\MyFinTechHomework\\Week4_31052021\\Assignment\\VAS.csv'\n",
    "\n",
    "ivv_df = pd.read_csv(ivv, infer_datetime_format=True, parse_dates=True, index_col='Date')\n",
    "ivv_drop_df = ivv_df.drop(columns=['Open', 'High', 'Low', 'Volume'])\n",
    "ivv_drop_df.columns = ['IVV']\n",
    "ivv_drop_df.drop_duplicates(inplace=True)\n",
    "ivv_drop_df.index = ivv_drop_df.index.normalize()\n",
    "ivv_final_df = ivv_drop_df.loc['2015-01-01':'2018-12-30']\n",
    "ivv_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 2nd stock\n",
    "vap_df = pd.read_csv(vap, infer_datetime_format=True, parse_dates=True, index_col='Date')\n",
    "vap_drop_df = vap_df.drop(columns=['Open', 'High', 'Low', 'Volume'])\n",
    "vap_drop_df.columns = ['VAP']\n",
    "vap_drop_df.drop_duplicates(inplace=True)\n",
    "vap_drop_df.index = vap_drop_df.index.normalize()\n",
    "vap_final_df = vap_drop_df.loc['2015-01-01':'2018-12-30']\n",
    "vap_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 3rd stock\n",
    "vso_df = pd.read_csv(vso, infer_datetime_format=True, parse_dates=True, index_col='Date')\n",
    "vso_drop_df = vso_df.drop(columns=['Open', 'High', 'Low', 'Volume'])\n",
    "vso_drop_df.columns = ['VSO']\n",
    "vso_drop_df.drop_duplicates(inplace=True)\n",
    "vso_drop_df.index = vso_drop_df.index.normalize()\n",
    "vso_final_df = vso_drop_df.loc['2015-01-01':'2018-12-30']\n",
    "vso_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 4th stock\n",
    "vas_df = pd.read_csv(vas, infer_datetime_format=True, parse_dates=True, index_col='Date')\n",
    "vas_drop_df = vas_df.drop(columns=['Open', 'High', 'Low', 'Volume'])\n",
    "vas_drop_df.columns = ['VAS']\n",
    "vas_drop_df.drop_duplicates(inplace=True)\n",
    "vas_drop_df.index = vas_drop_df.index.normalize()\n",
    "vas_drop_df.loc['2015-01-01':'2018-12-30']\n",
    "vas_final_df = vas_drop_df.loc['2015-01-01':'2018-12-30']\n",
    "vas_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all stocks in a single DataFrame. # Reset Date index. Reorganize portfolio data by having a column per symbol\n",
    "ivv_reset = ivv_final_df.reset_index()\n",
    "vap_reset = vap_final_df.reset_index()\n",
    "vso_reset = vso_final_df.reset_index()\n",
    "vas_reset = vas_final_df.reset_index()\n",
    "\n",
    "combined_own_df = pd.concat([ivv_reset['Date'], ivv_reset['IVV'], vap_reset['VAP'], vso_reset['VSO'], vas_reset['VAS']], axis='columns', join='inner')\n",
    "combined_own_idx_df = combined_own_df.set_index('Date')\n",
    "combined_own_idx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "daily_returns_own = combined_own_idx_df.pct_change()\n",
    "\n",
    "# Drop NAs\n",
    "daily_returns_own.isna().sum()\n",
    "daily_returns_own = daily_returns_own.dropna()\n",
    "\n",
    "#daily_returns_own.isna().sum()\n",
    "\n",
    "# Display sample data\n",
    "daily_returns_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot daily returns\n",
    "plot1_own = daily_returns_own['IVV'].plot(figsize=(10,7), color='blue', title='Daily returns')\n",
    "daily_returns_own['VAP'].plot(ax=plot1_own, color='red', alpha=0.8)\n",
    "daily_returns_own['VSO'].plot(ax=plot1_own, color='green', linestyle='dotted', alpha=0.5)\n",
    "daily_returns_own['VAS'].plot(ax=plot1_own, color='purple', linestyle='dashed', alpha=0.3)\n",
    "\n",
    "plot1_own.set_xlabel('Year')\n",
    "plot1_own.legend(['IVV', 'VAP', 'VSO', 'VAS'])\n",
    "plot1_own.figure.savefig('CustomPorfolio_DailyReturns.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights (equal weighting)\n",
    "weights = [0.33, 0.33, 0.33, 0.33]\n",
    "\n",
    "# Calculate portfolio return\n",
    "own_portfolio_return = daily_returns_own.dot(weights)\n",
    "\n",
    "# Display sample data\n",
    "own_portfolio_return.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join your portfolio returns to the DataFrame that contains all of the portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join your returns DataFrame to the original returns DataFrame\n",
    "new_df = pd.concat([combined_df, own_portfolio_return], axis='columns', join='inner')\n",
    "new_rename_df = new_df.rename(columns={int(0): 'ThapaPortfolio'})\n",
    "new_rename_df.head()\n",
    "new_rename_df.tail()\n",
    "#new_rename_df.shape                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only compare dates where return data exists for all the stocks (drop NaNs)\n",
    "new_rename_drop_df = new_rename_df.dropna()\n",
    "new_rename_drop_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the risk analysis with your portfolio to see how it compares to the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "soros_std_annl = new_rename_drop_df['SOROS FUND MANAGEMENT LLC'].std() *np.sqrt(252)\n",
    "paulson_std_annl = new_rename_drop_df['PAULSON & CO.INC. '].std() *np.sqrt(252)\n",
    "tiger_std_annl = new_rename_drop_df['TIGER GLOBAL MANAGEMENT LLC'].std() *np.sqrt(252)\n",
    "berkshire_std_annl = new_rename_drop_df['BERKSHIRE HATHAWAY INC'].std() *np.sqrt(252)\n",
    "algo1_std_annl = new_rename_drop_df['Algo 1'].std() *np.sqrt(252)\n",
    "algo2_std_annl = new_rename_drop_df['Algo 2'].std() *np.sqrt(252)\n",
    "sp500_std_annl = new_rename_drop_df['SP500'].std() *np.sqrt(252)\n",
    "thapa_annl = new_rename_drop_df['ThapaPortfolio'].std() *np.sqrt(252)\n",
    "\n",
    "# Print std devs for each portfolio\n",
    "print(f\"Soros' std is {soros_std_annl}\")\n",
    "print(f\"Paulson's std is {paulson_std_annl}\")\n",
    "print(f\"Tiger's std is {tiger_std_annl}\")\n",
    "print(f\"Berkshire's std is {berkshire_std_annl}\")\n",
    "print(f\"Algo1's std is {algo1_std_annl}\")\n",
    "print(f\"Algo2's std is {algo2_std_annl}\")\n",
    "print(f\"SP500's std is {sp500_std_annl}\")\n",
    "print(f\"Thapa's std is {thapa_annl}\")\n",
    "\n",
    "# Create list and plot std devs\n",
    "std_annl_list = [soros_std_annl, paulson_std_annl, tiger_std_annl, berkshire_std_annl, algo1_std_annl, algo2_std_annl, sp500_std_annl, thapa_annl]\n",
    "row_names = ['soros', 'paulson', 'tiger', 'berkshire', 'algo1', 'algo2', 'sp500_std', 'thapa']\n",
    "\n",
    "std_annl_list_df = pd.DataFrame(std_annl_list, row_names)\n",
    "plot2 = std_annl_list_df.plot(marker='o', color='r', markerfacecolor='blue', xlabel='Ticker', ylabel='Annualised std dev')\n",
    "plot2.figure.savefig('CustomPorfolio_AnnualisedStdDev.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot rolling `std` with 21-day window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling standard deviation\n",
    "roll_std_soros = new_rename_drop_df['SOROS FUND MANAGEMENT LLC'].rolling(window=21).std()\n",
    "roll_std_paulson = new_rename_drop_df['PAULSON & CO.INC. '].rolling(window=21).std()\n",
    "roll_std_tiger = new_rename_drop_df['TIGER GLOBAL MANAGEMENT LLC'].rolling(window=21).std()\n",
    "roll_std_berkshire= new_rename_drop_df['BERKSHIRE HATHAWAY INC'].rolling(window=21).std()\n",
    "roll_std_algo1 = new_rename_drop_df['Algo 1'].rolling(window=21).std()\n",
    "roll_std_algo2 = new_rename_drop_df['Algo 2'].rolling(window=21).std()\n",
    "roll_std_sp500 = new_rename_drop_df['SP500'].rolling(window=21).std()\n",
    "roll_std_thapa = new_rename_drop_df['ThapaPortfolio'].rolling(window=21).std()\n",
    "\n",
    "\n",
    "# Plot the rolling standard deviation\n",
    "plot3 = roll_std_soros.plot(figsize=(15, 10), title='Rolling 21-day standard deviation', color='y')\n",
    "roll_std_paulson.plot(ax=plot3, color='r', linestyle='dotted', alpha=0.9)\n",
    "roll_std_tiger.plot(ax=plot3, color='g', linestyle='dashdot', alpha=0.8)\n",
    "roll_std_berkshire.plot(ax=plot3, color='b', linestyle='dotted', alpha=0.7)\n",
    "roll_std_algo1.plot(ax=plot3, color='m', linestyle='dotted', alpha=0.6)\n",
    "roll_std_algo2.plot(ax=plot3, color='c', alpha=0.5)\n",
    "roll_std_sp500.plot(ax=plot3, color='k')\n",
    "roll_std_thapa.plot(ax=plot3, color='blue', alpha=0.8, linestyle='dashed')\n",
    "\n",
    "\n",
    "plot3.legend(['Soros', 'Paulson', 'Tiger', 'Berkshire', 'Algo1', 'Algo2', 'SP500', 'Thapa'])\n",
    "plot3.set_xlabel('Year')\n",
    "plot3.set_ylabel('std dev')\n",
    "plot3.figure.savefig('CustomPorfolio_StdDev21DayRoll.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the correlation\n",
    "correlation_all = new_rename_drop_df.corr()\n",
    "correlation_all\n",
    "\n",
    "# Figure settings\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "h = plt.axes()\n",
    "sns.heatmap(correlation_all, vmin=-1, vmax=1, annot=True, cmap=cmap)\n",
    "sns.set(rc={'figure.figsize':(10,7)})\n",
    "h.set_title('Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation plot as above but only the lower triangle for easier interpretation\n",
    "matrix = np.triu(correlation_all)\n",
    "plot4 = sns.heatmap(correlation_all, vmin=-1, vmax=1, annot=True, cmap=cmap, mask=matrix)\n",
    "plot4.figure.savefig('CustomPorfolio_Correlations.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Plot the 60-day Rolling Beta for Your Portfolio compared to the S&P 60 TSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance of a single portfolio\n",
    "cov_thapa = new_rename_drop_df['ThapaPortfolio'].rolling(window=60).cov(new_rename_drop_df['SP500'])\n",
    "\n",
    "# Calculate variance of S&P TSX\n",
    "var_SP500 = new_rename_drop_df['SP500'].rolling(window=60).var()\n",
    "\n",
    "# Computing beta\n",
    "beta_thapa = cov_thapa / var_SP500\n",
    "print(f\"The average beta score for ThapaPortfolio is {beta_thapa.mean()}. \")\n",
    "print()\n",
    "\n",
    "# Plot beta trend\n",
    "plot_own_beta = beta_thapa.plot(figsize=(15,10), color='blue')\n",
    "\n",
    "# Set the legend of the figure\n",
    "plot_own_beta.set_xlabel('Year')\n",
    "plot_own_beta.set_ylabel('Beta value')\n",
    "plot_own_beta.figure.savefig('CustomPortFolio_Beta.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Annualzied Sharpe Ratios\n",
    "sharpe_ratio_all = (new_rename_drop_df.mean()*252) / (new_rename_drop_df.std()*np.sqrt(252))\n",
    "sharpe_ratio_all.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "sharpe_ratio_thapa = sharpe_ratio_all.plot(kind='bar',\n",
    "                                           figsize=(10, 7),\n",
    "                                           title='Sharpe ratios for each portfolio', \n",
    "                                           edgecolor='red', \n",
    "                                           color='black',\n",
    "                                           ylabel='Sharpe ratio',\n",
    "                                           xlabel='Portfolios')\n",
    "sharpe_ratio_thapa.figure.savefig('CustomPortfolio_SharpeRatio.png',  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot to visually show risk\n",
    "data_to_plot = [new_rename_drop_df['SOROS FUND MANAGEMENT LLC'], \n",
    "                new_rename_drop_df['PAULSON & CO.INC. '],\n",
    "                new_rename_drop_df['TIGER GLOBAL MANAGEMENT LLC'],\n",
    "                new_rename_drop_df['BERKSHIRE HATHAWAY INC'],\n",
    "                new_rename_drop_df['Algo 1'],\n",
    "                new_rename_drop_df['Algo 2'],\n",
    "                new_rename_drop_df['SP500'],\n",
    "                new_rename_drop_df['ThapaPortfolio']]\n",
    "\n",
    "flierprops = dict(marker='o', markerfacecolor='r', markersize=5, markeredgecolor='k')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "box = plt.boxplot(data_to_plot,\n",
    "                  labels =['Soros', 'Paulson', 'Tiger', 'Berkshire', 'Algo1', 'Algo2', 'SP500', 'Thapa'],\n",
    "                  flierprops=flierprops,\n",
    "                  showmeans=True)\n",
    "\n",
    "ax.set_title('Daily returns across all portfolios')\n",
    "ax.set_xlabel('Ticker')\n",
    "\n",
    "fig.savefig('CustomPortfolio_DailyReturns.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does your portfolio do?\n",
    "\n",
    "Compared to the other portfolios, my portfolio is conservative because\n",
    "\n",
    "- Annualised std: 1.8 suggesting less variability in daily returns compared to all portfolios except Paulson. Therefore, a stable portfolio but with less potential for good returns. \n",
    "- Beta (market volatility): 0.41 suggesting the portfolio is less volatile than the market, and further supports the interpretation from annualised std above. \n",
    "- SharpeRatio (relative risk): 0.45 is very conservative due to low risk "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
